{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from neuralhydrology.evaluation import metrics\n",
    "from neuralhydrology.nh_run import start_run, eval_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology/examples/07-DifferentialCFE-Model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n",
      "2024-07-17 23:28:30,429: Logging to /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology/examples/07-DifferentialCFE-Model/runs/test_run_1707_232830/output.log initialized.\n",
      "2024-07-17 23:28:30,430: ### Folder structure created at /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology/examples/07-DifferentialCFE-Model/runs/test_run_1707_232830\n",
      "2024-07-17 23:28:30,430: ### Run configurations for test_run\n",
      "2024-07-17 23:28:30,431: experiment_name: test_run\n",
      "2024-07-17 23:28:30,431: train_basin_file: 1_basin.txt\n",
      "2024-07-17 23:28:30,432: validation_basin_file: 1_basin.txt\n",
      "2024-07-17 23:28:30,432: test_basin_file: 1_basin.txt\n",
      "2024-07-17 23:28:30,433: train_start_date: 1999-10-01 00:00:00\n",
      "2024-07-17 23:28:30,433: train_end_date: 2008-09-30 00:00:00\n",
      "2024-07-17 23:28:30,434: validation_start_date: 1980-10-01 00:00:00\n",
      "2024-07-17 23:28:30,435: validation_end_date: 1989-09-30 00:00:00\n",
      "2024-07-17 23:28:30,435: test_start_date: 1989-10-01 00:00:00\n",
      "2024-07-17 23:28:30,436: test_end_date: 1999-09-30 00:00:00\n",
      "2024-07-17 23:28:30,436: device: cpu\n",
      "2024-07-17 23:28:30,437: validate_every: 3\n",
      "2024-07-17 23:28:30,437: validate_n_random_basins: 1\n",
      "2024-07-17 23:28:30,437: metrics: ['NSE']\n",
      "2024-07-17 23:28:30,438: model: hybrid_model\n",
      "2024-07-17 23:28:30,438: conceptual_model: shm\n",
      "2024-07-17 23:28:30,439: head: regression\n",
      "2024-07-17 23:28:30,439: output_activation: linear\n",
      "2024-07-17 23:28:30,439: hidden_size: 20\n",
      "2024-07-17 23:28:30,440: initial_forget_bias: 3\n",
      "2024-07-17 23:28:30,440: output_dropout: 0.4\n",
      "2024-07-17 23:28:30,441: warmup_period: 100\n",
      "2024-07-17 23:28:30,441: optimizer: Adam\n",
      "2024-07-17 23:28:30,441: loss: MSE\n",
      "2024-07-17 23:28:30,441: learning_rate: {0: 0.01, 30: 0.005, 40: 0.001}\n",
      "2024-07-17 23:28:30,442: batch_size: 256\n",
      "2024-07-17 23:28:30,442: epochs: 25\n",
      "2024-07-17 23:28:30,443: clip_gradient_norm: 1\n",
      "2024-07-17 23:28:30,444: predict_last_n: 1\n",
      "2024-07-17 23:28:30,444: seq_length: 365\n",
      "2024-07-17 23:28:30,444: num_workers: 8\n",
      "2024-07-17 23:28:30,445: log_interval: 5\n",
      "2024-07-17 23:28:30,446: log_tensorboard: True\n",
      "2024-07-17 23:28:30,446: log_n_figures: 1\n",
      "2024-07-17 23:28:30,447: save_weights_every: 1\n",
      "2024-07-17 23:28:30,447: dataset: camels_us\n",
      "2024-07-17 23:28:30,448: data_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/Code/data/CAMELS_US\n",
      "2024-07-17 23:28:30,448: forcings: ['maurer', 'daymet', 'nldas']\n",
      "2024-07-17 23:28:30,449: dynamic_inputs: ['PRCP(mm/day)_nldas', 'PRCP(mm/day)_maurer', 'prcp(mm/day)_daymet', 'srad(W/m2)_daymet', 'tmax(C)_daymet', 'tmin(C)_daymet', 'vp(Pa)_daymet']\n",
      "2024-07-17 23:28:30,449: duplicate_features: ['PRCP(mm/day)_nldas', 'tmax(C)_daymet', 'tmin(C)_daymet']\n",
      "2024-07-17 23:28:30,449: dynamic_conceptual_inputs: ['PRCP(mm/day)_nldas_copy1', 'tmax(C)_daymet_copy1', 'tmin(C)_daymet_copy1']\n",
      "2024-07-17 23:28:30,450: custom_normalization: {'PRCP(mm/day)_nldas_copy1': {'centering': 'None', 'scaling': 'None'}, 'tmax(C)_daymet_copy1': {'centering': 'None', 'scaling': 'None'}, 'tmin(C)_daymet_copy1': {'centering': 'None', 'scaling': 'None'}, 'QObs(mm/d)': {'centering': 'None', 'scaling': 'None'}}\n",
      "2024-07-17 23:28:30,450: target_variables: ['QObs(mm/d)']\n",
      "2024-07-17 23:28:30,451: clip_targets_to_zero: ['QObs(mm/d)']\n",
      "2024-07-17 23:28:30,451: number_of_basins: 1\n",
      "2024-07-17 23:28:30,452: run_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology/examples/07-DifferentialCFE-Model/runs/test_run_1707_232830\n",
      "2024-07-17 23:28:30,453: train_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology/examples/07-DifferentialCFE-Model/runs/test_run_1707_232830/train_data\n",
      "2024-07-17 23:28:30,453: img_log_dir: /Users/ziyu/Library/CloudStorage/OneDrive-ColoradoSchoolofMines/Documents/College/ResearchStuff/NextGen/neuralhydrology/examples/07-DifferentialCFE-Model/runs/test_run_1707_232830/img_log\n",
      "2024-07-17 23:28:30,483: ### Device cpu will be used for training\n",
      "2024-07-17 23:28:30,484: Loading basin data into xarray data set.\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
      "2024-07-17 23:28:30,640: Create lookup table and convert to pytorch tensor\n",
      "100%|██████████| 1/1 [00:00<00:00, 21.55it/s]\n",
      "# Epoch 1:   0%|          | 0/13 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# fall back to CPU-only mode\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     start_run(config_file\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasin_hybrid.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m), gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/neuralhydrology/nh_run.py:76\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(config_file, gpu)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gpu \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     74\u001b[0m     config\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 76\u001b[0m start_training(config)\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/neuralhydrology/training/train.py:20\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown head \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m trainer\u001b[38;5;241m.\u001b[39minitialize_training()\n\u001b[0;32m---> 20\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain_and_validate()\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/neuralhydrology/training/basetrainer.py:214\u001b[0m, in \u001b[0;36mBaseTrainer.train_and_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    212\u001b[0m         param_group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlearning_rate[epoch]\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch(epoch\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[1;32m    215\u001b[0m avg_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_logger\u001b[38;5;241m.\u001b[39msummarise()\n\u001b[1;32m    216\u001b[0m loss_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m avg_losses\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/neuralhydrology/training/basetrainer.py:296\u001b[0m, in \u001b[0;36mBaseTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    293\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpre_model_hook(data, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# get predictions\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_sampler_y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m k: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m k, data\u001b[38;5;241m.\u001b[39mkeys()):\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/neuralhydrology/modelzoo/hybridmodel.py:65\u001b[0m, in \u001b[0;36mHybridModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     62\u001b[0m lstm_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_out)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# get predictions\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconceptual_model(x_conceptual\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_d_c\u001b[39m\u001b[38;5;124m'\u001b[39m][:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mwarmup_period:, :], lstm_out\u001b[38;5;241m=\u001b[39mlstm_out)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dCFE_env/lib/python3.12/site-packages/neuralhydrology/modelzoo/shm.py:66\u001b[0m, in \u001b[0;36mSHM.forward\u001b[0;34m(self, x_conceptual, lstm_out)\u001b[0m\n\u001b[1;32m     63\u001b[0m klu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.90\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mx_conceptual\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# land use correction factor [-]\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# auxiliary vectors to accelerate the execution of the hydrological model\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m t_mean \u001b[38;5;241m=\u001b[39m (x_conceptual[:, :, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m x_conceptual[:, :, \u001b[38;5;241m3\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     67\u001b[0m temp_mask \u001b[38;5;241m=\u001b[39m t_mean \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     68\u001b[0m snow_melt \u001b[38;5;241m=\u001b[39m t_mean \u001b[38;5;241m*\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 2 with size 3"
     ]
    }
   ],
   "source": [
    "\n",
    "# by default we assume that you have at least one CUDA-capable NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU\")\n",
    "    start_run(config_file=Path(\"basin_hybrid.yml\"))\n",
    "\n",
    "# fall back to CPU-only mode\n",
    "else:\n",
    "    print(\"CPU\")\n",
    "    start_run(config_file=Path(\"basin_hybrid.yml\"), gpu=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dCFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
